Time (%),Total Time (ns),Instances,Avg (ns),Med (ns),Min (ns),Max (ns),StdDev (ns),Name
20.6,35762532973,1404,25471889.6,1164103.0,1055,230170546,56683750.8,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long long)3>>(int, T2, T3)"
18.8,32733996256,864,37886569.7,3292984.0,1072231,304035804,62325435.0,"void <unnamed>::softmax_warp_backward<float, float, float, (int)9, (bool)0, (bool)0>(T2 *, const T1 *, const T1 *, int, int, int, const bool *)"
8.3,14349855389,648,22144838.6,667937.0,257562,123066348,31983035.8,ampere_fp16_sgemm_fp16_64x64_tn
6.8,11772627677,864,13625726.5,2423977.5,804431,115852519,20732473.6,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::masked_scale_kernel<bool, float, float>(at::Tensor &, const at::Tensor &, const at::Tensor &, T3)::[lambda(float, bool) (instance 1)], std::array<char *, (unsigned long long)3>>(int, T2, T3)"
5.9,10269290928,19898,516096.6,2143.0,1024,115064186,4465990.1,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T4, T5, T6, T7)"
5.1,8868420183,28404,312224.3,1696.0,928,111707977,1811821.0,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::float16_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda(float) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
4.0,6987919676,1728,4043935.0,2259275.0,688464,13656334,4316317.3,"void <unnamed>::softmax_warp_forward<float, float, float, (int)9, (bool)0, (bool)0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)"
3.8,6658507455,1296,5137737.2,1414848.5,813582,14619359,5631829.3,"void at::native::<unnamed>::fused_dropout_kernel_vec<float, float, unsigned int, (int)1, (int)4, bool>(at::cuda::detail::TensorInfo<const T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T6, T3>, T3, T2, at::PhiloxCudaState)"
3.1,5322451225,2160,2464097.8,850989.5,3264,10230317,3080457.2,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
2.5,4364232824,2160,2020478.2,204171.5,1856,81881702,4284155.5,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
1.5,2646789050,16784,157697.2,5952.0,1119,14175051,445261.2,"void cudnn::engines_precompiled::nchwToNhwcKernel<__half, __half, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
1.2,2150665782,540,3982714.4,122701.5,47167,181477204,13652791.0,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, (int)4, (int)4>>(T3)"
1.2,2094186925,2808,745793.1,33903.5,3999,4954099,1206382.7,"void at::native::batch_norm_backward_kernel<c10::Half, c10::Half, float, int>(at::GenericPackedTensorAccessor<const T1, (unsigned long long)3, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T1, (unsigned long long)3, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<T1, (unsigned long long)3, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<T2, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<T2, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T2, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T2, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T2, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T3, (unsigned long long)1, at::DefaultPtrTraits, T4>, at::GenericPackedTensorAccessor<const T3, (unsigned long long)1, at::DefaultPtrTraits, T4>, bool, T3)"
1.0,1808591940,1728,1046638.9,663776.5,231642,3653617,1043316.3,void cutlass::Kernel2<cutlass_75_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align1>(T1::Params)
0.8,1443516843,432,3341474.2,3343062.0,3192187,4312548,120253.1,"void at::native::<unnamed>::fused_dropout_kernel_vec<float, float, unsigned int, (int)1, (int)2, bool>(at::cuda::detail::TensorInfo<const T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T6, T3>, T3, T2, at::PhiloxCudaState)"
0.8,1387843114,864,1606299.9,1625179.5,256026,3708902,1341530.1,ampere_fp16_sgemm_fp16_64x64_nn
0.7,1230351872,4428,277857.2,18079.0,1919,10016335,454653.9,"void at::native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)"
0.6,1084831980,864,1255592.6,271897.5,5632,5109574,1862759.8,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.6,1057061212,7998,132165.7,2656.0,1120,3143413,333910.8,"void cudnn::engines_precompiled::nhwcToNchwKernel<__half, __half, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
0.6,1054260307,582,1811443.8,500565.0,5504,7771239,1719476.6,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.6,990202914,922,1073972.8,494181.0,7487,6673165,1718442.2,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x128x32_stage4_warpsize1x4x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.5,955475798,8100,117960.0,5792.0,1215,2906876,346008.9,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<c10::Half>, std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.5,915222443,2808,325933.9,9536.0,1375,1779993,559656.6,"void at::native::batch_norm_transform_input_kernel<c10::Half, c10::Half, float, (bool)1, int>(at::GenericPackedTensorAccessor<const T1, (unsigned long long)3, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<T1, (unsigned long long)3, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<std::conditional<T4, T3, T2>::type, (unsigned long long)1, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<std::conditional<T4, T3, T2>::type, (unsigned long long)1, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<const T2, (unsigned long long)1, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<const T2, (unsigned long long)1, at::RestrictPtrTraits, T5>, T3)"
0.5,900246651,864,1041952.1,644193.5,205724,3634000,1048768.8,void cutlass::Kernel2<cutlass_75_tensorop_f16_s1688gemm_f16_128x64_nt_align1>(T1::Params)
0.5,890510574,864,1030683.5,660801.5,191259,3058814,1060595.6,void cutlass::Kernel2<cutlass_75_tensorop_f16_s1688gemm_f16_64x64_nt_align1>(T1::Params)
0.5,879420427,2808,313183.9,10784.0,3552,1796056,532467.6,"void at::native::batch_norm_collect_statistics_kernel<at::native::Var, c10::Half, c10::Half, float, int>(at::GenericPackedTensorAccessor<const T2, (unsigned long long)3, at::RestrictPtrTraits, T5>, T4, T4, at::GenericPackedTensorAccessor<T4, (unsigned long long)1, at::RestrictPtrTraits, T5>, at::GenericPackedTensorAccessor<T4, (unsigned long long)1, at::RestrictPtrTraits, T5>)"
0.5,866290704,864,1002651.3,546467.5,186684,3577331,1055928.5,void cutlass::Kernel2<cutlass_75_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_tn_align1>(T1::Params)
0.5,846446569,260,3255563.7,3735946.0,15039,7000794,1271224.5,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x256x32_stage3_warpsize1x4x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.5,794010380,33264,23870.0,5472.0,1504,530707,52289.1,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.4,766098238,578,1325429.5,173148.0,7743,5987313,2077310.3,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.4,749972189,14364,52211.9,10879.0,1407,6901754,97668.5,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.4,675743880,1330,508078.1,145533.0,6368,4755289,1155705.0,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_alignc8_execute_kernel__5x_cudnn
0.3,588311281,2160,272366.3,6528.0,991,1527227,486027.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::leaky_relu_backward_kernel(at::TensorIteratorBase &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half, c10::Half) (instance 1)], std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.3,586920959,864,679306.7,162460.5,3264,2942048,993729.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::AUnaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.3,521260843,236,2208732.4,2314652.5,14528,4297080,541730.5,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_alignc2_execute_kernel__5x_cudnn
0.3,487645815,2700,180609.6,14223.5,1888,1124615,278316.1,"void at::native::<unnamed>::layer_norm_grad_input_kernel_vectorized<float, float>(const T1 *, const T1 *, const T2 *, const T2 *, const T1 *, T1 *, int)"
0.3,482494268,464,1039858.3,686799.5,17984,17745370,1340133.9,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x32x64_stage1_warpsize2x2x1_g1_tensor16x8x16_aligna4_alignc4_execute_kernel__5x_cudnn
0.2,388169730,26352,14730.2,2112.0,735,1959571,49693.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<c10::Half>, std::array<char *, (unsigned long long)1>>(int, T2, T3)"
0.2,382560060,5292,72290.3,7872.0,2239,3789797,156320.8,"void at::native::<unnamed>::fused_dropout_kernel_vec<c10::Half, float, unsigned int, (int)1, (int)8, bool>(at::cuda::detail::TensorInfo<const T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T6, T3>, T3, T2, at::PhiloxCudaState)"
0.2,373800948,864,432640.0,462166.0,145533,1153414,281644.3,void cutlass::Kernel2<cutlass_75_tensorop_f16_s1688gemm_f16_128x64_nn_align1>(T1::Params)
0.2,360117511,2160,166721.1,4288.0,896,1255076,318777.2,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::leaky_relu_kernel(at::TensorIteratorBase &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.2,303987319,216,1407348.7,1392849.5,1380962,1849496,43720.3,"void at::native::reduce_kernel<(int)256, (int)2, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, (int)4, (int)4>>(T3)"
0.2,300466094,3888,77280.4,19439.5,7391,488758,107873.1,"void at::native::roll_cuda_kernel<float>(const T1 *, T1 *, long long, long long, long long, long long, long long, long long)"
0.1,239726515,1296,184974.2,6208.0,4192,961193,262611.3,"void at::native::reduce_kernel<(int)128, (int)4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, (int)4, (int)4>>(T3)"
0.1,238494721,3456,69008.9,23296.0,7840,464246,86632.5,ampere_fp16_s1688gemm_fp16_128x128_ldg8_relu_f2f_stages_32x1_tn
0.1,223048402,1728,129078.9,31087.0,2367,2250766,178530.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase &, at::native::GeluType)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.1,215643025,6,35940504.2,22149136.5,11089304,74994822,30339130.8,"void cudnn::cnn::wgrad2d_grouped_direct_kernel<(bool)1, (bool)1, int, __half, float, float>(cudnn::cnn::WgradGroupedDirectParams, const T4 *, const T4 *, T4 *, T6, T6)"
0.1,213942671,1412,151517.5,146701.0,8416,1327808,126291.8,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_32x1_nn_align8>(T1::Params)
0.1,195559421,700,279370.6,102094.0,5152,8062592,568090.7,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.1,183002503,232,788803.9,591235.0,20223,1345343,382642.3,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_32x1_nt_align8>(T1::Params)
0.1,169075770,2592,65229.8,7711.5,1216,530932,119368.3,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::masked_scale_kernel<bool, c10::Half, float>(at::Tensor &, const at::Tensor &, const at::Tensor &, T3)::[lambda(c10::Half, bool) (instance 1)], std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.1,158765847,864,183756.8,46703.0,3104,762382,260438.0,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::GeluBackwardCUDAKernelImpl(at::TensorIteratorBase &, at::native::GeluType)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half, c10::Half) (instance 1)], std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.1,137160432,226,606904.6,14176.0,7392,1707835,607985.4,ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_nn
0.1,136461187,610,223706.9,87710.0,7072,16590677,1200969.0,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.1,131130589,864,151771.5,145149.0,35551,2252271,135118.1,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_128x1_tn_align8>(T1::Params)
0.1,119575836,3564,33551.0,9824.0,4639,197276,47247.8,"void at::native::reduce_kernel<(int)128, (int)4, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, c10::Half, (int)4, (int)4>>(T3)"
0.1,111897746,502,222903.9,105038.0,7264,10454343,782950.8,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.1,107226985,432,248210.6,237019.0,235291,2051793,90334.4,"void at::native::<unnamed>::GammaBetaBackwardCUDAKernelTemplate<float, float, (unsigned int)32, (unsigned int)1, (unsigned int)32, (bool)1, (bool)0>(long long, long long, const T1 *, const T1 *, const T2 *, const T2 *, T1 *, T1 *)"
0.1,106610804,1728,61696.1,15680.0,3839,485173,80819.4,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,102218341,2054,49765.5,12224.0,4832,413462,91257.5,ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_64x3_nt
0.1,101725298,402,253048.0,161804.5,6016,12666035,980095.1,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.1,98172518,2592,37875.2,18831.5,7327,339257,40353.1,"void at::native::roll_cuda_kernel<c10::Half>(const T1 *, T1 *, long long, long long, long long, long long, long long, long long)"
0.1,92615343,1944,47641.6,36847.0,3232,1498940,58021.9,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,91457785,864,105853.9,105357.5,102718,399703,10065.4,"void at::native::vectorized_gather_kernel<(int)16, long long>(char *, char *, T2 *, int, long long, long long, long long, long long, bool)"
0.1,90825736,4109,22104.1,2624.0,736,200924,38799.4,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<float>, std::array<char *, (unsigned long long)1>>(int, T2, T3)"
0.1,90512372,240,377134.9,306905.5,13279,4613073,465835.9,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8_execute_kernel__5x_cudnn
0.1,89641149,232,386384.3,542436.0,111934,4015679,398801.6,"void implicit_convolveNd_sgemm<__half, (int)3, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T1 *, const T1 *, kernel_convNd_params, unsigned long long, int, float, float, int, const T1 *, const T1 *, bool, bool)"
0.0,86096976,134,642514.7,529764.5,32991,5542299,674846.0,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna4_alignc4_execute_kernel__5x_cudnn
0.0,80849566,648,124767.8,130365.0,9407,308536,92548.0,void cutlass::Kernel2<cutlass_80_tensorop_s16816gemm_f16_64x64_32x6_nt_align8>(T1::Params)
0.0,73822558,42,1757680.0,251962.0,27296,16018690,3705041.5,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,71556070,278,257395.9,33391.5,6272,11059256,1362263.9,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,69667874,50,1393357.5,160012.0,7488,10789535,2908297.2,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,67697333,20,3384866.6,773614.0,52927,17501664,5750961.7,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x2_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,66488636,648,102605.9,25983.0,18655,288570,113545.2,ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_nt
0.0,65855937,36,1829331.6,676895.5,9408,15198294,3709849.5,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize16x64x64_stage1_warpsize1x4x1_g1_tensor16x8x16_aligna4_alignc4_execute_kernel__5x_cudnn
0.0,60609626,14,4329259.0,1796917.5,39903,15855879,5655288.3,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize32x16x64_stage1_warpsize2x1x1_g1_tensor16x8x8_aligna8_alignc8_execute_kernel__5x_cudnn
0.0,58022611,112,518059.0,518052.0,434581,559380,21193.7,void cutlass::Kernel2<cutlass_80_wmma_tensorop_s161616gemm_f16_16x16_128x2_tn_align8>(T1::Params)
0.0,57171643,136,420379.7,57055.0,37567,13959507,1884255.7,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,56672651,114,497128.5,493509.5,404278,607314,29997.8,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_16x16_32x1_nn_align8>(T1::Params)
0.0,54256344,864,62796.7,62494.5,59487,338968,9463.8,"void <unnamed>::indexing_backward_kernel_small_stride<float>(const long long *, const long long *, const T1 *, T1 *, long long, long long, long long, long long, bool)"
0.0,50021112,32,1563159.8,709167.0,46719,12914860,3058651.0,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize16x64x64_stage1_warpsize1x4x1_g1_tensor16x8x16_aligna2_alignc4_execute_kernel__5x_cudnn
0.0,49963775,114,438278.7,425590.5,419414,644274,35669.4,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_32x1_nn_align2>(T1::Params)
0.0,46277288,34,1361096.7,282745.0,7648,7362127,2184447.3,sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,45261588,432,104772.2,104734.0,103389,106462,554.4,"void at::native::<unnamed>::GammaBetaBackwardCUDAKernelTemplate<float, float, (unsigned int)32, (unsigned int)32, (unsigned int)256, (bool)0, (bool)0>(long long, long long, const T1 *, const T1 *, const T2 *, const T2 *, T1 *, T1 *)"
0.0,44566568,248,179703.9,74510.0,7743,8323001,838846.3,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_strided_execute_kernel__5x_cudnn
0.0,44342356,38,1166904.1,179083.5,7360,6865498,2003111.5,sm86_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x32x32_stage5_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,40787852,40,1019696.3,122669.0,6944,10638080,2554614.8,sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,39623158,108,366881.1,352888.0,346680,461782,31099.9,"void at::native::<unnamed>::cunn_SpatialSoftMaxBackward<c10::Half, float, float, at::native::<unnamed>::SoftMaxBackwardEpilogue>(T1 *, const T3 *, const T3 *, unsigned int, unsigned int, unsigned int)"
0.0,37200760,3024,12301.8,3200.0,1727,112350,21078.6,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,37151121,1188,31272.0,14112.0,3007,361016,71684.1,"void at::native::<unnamed>::GammaBetaBackwardCUDAKernelTemplate<float, float, (unsigned int)32, (unsigned int)32, (unsigned int)256, (bool)0, (bool)1>(long long, long long, const T1 *, const T1 *, const T2 *, const T2 *, T1 *, T1 *)"
0.0,35821001,12231,2928.7,1183.0,927,156125,10176.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<float>, std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.0,34489639,142,242884.8,11328.0,5344,7737191,1029248.0,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,34141536,138,247402.4,104429.5,8096,7751462,911760.3,sm86_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x32_stage3_warpsize4x1x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,32161487,864,37223.9,37583.0,17472,78751,19785.4,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_32x1_tn_align8>(T1::Params)
0.0,29452156,22,1338734.4,288537.0,10751,8018785,2421199.8,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_strided_execute_kernel__5x_cudnn
0.0,28928058,216,133926.2,129916.5,127869,187068,13153.3,ampere_fp16_sgemm_fp16_128x64_tn
0.0,25937314,104,249397.3,30175.5,8704,1262883,394480.7,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListScalarListMetadata<float, (int)3>, at::native::<unnamed>::PointwiseOpScalarListFunctor<float, (int)3, (int)3, (int)0>, std::divides<float>>(T1, T2, T3...)"
0.0,25847412,22,1174882.4,564578.5,86622,4728814,1369664.7,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc2_execute_kernel__5x_cudnn
0.0,24829328,32,775916.5,273561.5,1312,2776222,901667.4,"void cudnn::engines_precompiled::nchwToNhwcKernel<__half, float, float, (bool)0, (bool)1, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
0.0,24483826,20,1224191.3,401318.5,13952,6504131,1946383.6,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x16_alignc4_execute_kernel__5x_cudnn
0.0,24266710,20,1213335.5,399974.5,16799,6459236,1940547.9,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x16_alignc2_execute_kernel__5x_cudnn
0.0,22683431,108,210031.8,208875.5,203772,250810,7454.0,"void at::native::<unnamed>::cunn_SpatialSoftMaxBackward<c10::Half, float, c10::Half, at::native::<unnamed>::LogSoftMaxBackwardEpilogue>(T1 *, const T3 *, const T3 *, unsigned int, unsigned int, unsigned int)"
0.0,22439886,1082,20739.3,11999.5,7264,60990,9929.1,ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn
0.0,22070011,432,51088.0,49983.0,49278,78430,4271.0,ampere_fp16_s1688gemm_fp16_256x64_ldg8_relu_f2f_stages_32x1_tn
0.0,21234024,394,53893.5,12063.0,1312,887211,133700.0,"void xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_3<xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::Params_pre_hopper>(T1, int)"
0.0,20355424,104,195725.2,16048.0,5408,849293,309994.5,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)3>, at::native::<unnamed>::BinaryOpListAlphaFunctor<float, (int)3, (int)2, (int)2>, std::plus<float>, float>(T1, T2, T3...)"
0.0,19963877,104,191960.4,20111.0,5920,844877,303305.0,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)3>, at::native::<unnamed>::PointwiseOpScalarFunctor<float, (int)3, (int)3, (int)0>, std::multiplies<float>, float>(T1, T2, T3...)"
0.0,19848585,78,254469.0,298265.5,13535,547860,180727.7,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)2>, at::native::<unnamed>::TernaryOpScalarFunctor<float, (int)2, (int)2, (int)0>, at::native::LerpFunctor<float>, float>(T1, T2, T3...)"
0.0,19662667,28,702238.1,633105.0,32735,2320009,659898.5,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x16x64_stage1_warpsize2x1x1_g1_tensor16x8x16_aligna2_alignc4_execute_kernel__5x_cudnn
0.0,19643656,30,654788.5,294329.0,24319,1804405,649800.8,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x16x64_stage1_warpsize2x1x1_g1_tensor16x8x16_aligna2_alignc8_execute_kernel__5x_cudnn
0.0,19110331,864,22118.4,10223.5,2271,101949,25813.2,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,18233897,108,168832.4,165085.0,159292,363064,20683.3,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,17287940,108,160073.5,156253.0,152892,227195,14176.9,"void at::native::<unnamed>::cunn_SpatialSoftMaxForward<c10::Half, float, float, int, at::native::<unnamed>::SoftMaxForwardEpilogue>(T3 *, const T1 *, T4, T4, T4)"
0.0,17005827,108,157461.4,158588.5,132989,164060,5346.3,"void at::native::<unnamed>::nll_loss2d_forward_kernel<float, float, int>(T1 *, T1 *, const T1 *, const long long *, const T1 *, int, int, int, long long)"
0.0,16700473,366,45629.7,32799.0,4735,341784,32990.8,sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,14242072,1728,8241.9,8191.5,7264,9216,694.1,"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::detail::radix::policy_hub<long long, at::cuda::cub::detail::OpaqueType<(int)8>, unsigned long long>::Policy1000, (bool)0, long long, at::cuda::cub::detail::OpaqueType<(int)8>, unsigned long long, int, int, at_cuda_detail::cub::detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)"
0.0,13751218,108,127326.1,124414.0,117917,168572,10301.9,"void at::native::<unnamed>::nll_loss2d_backward_kernel<float>(T1 *, const T1 *, const long long *, const T1 *, const T1 *, bool, int, int, int, long long)"
0.0,13678992,52,263057.5,332136.5,42495,596468,216661.5,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)1>, at::native::<unnamed>::BinaryOpScalarFunctor<float, (int)1, (int)1, (int)0>, std::plus<float>, float>(T1, T2, T3...)"
0.0,13419443,52,258066.2,254666.5,37311,587219,221170.3,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)1>, at::native::<unnamed>::BinaryOpScalarFunctor<float, (int)1, (int)1, (int)0>, std::multiplies<float>, float>(T1, T2, T3...)"
0.0,13379989,78,171538.3,209131.0,9119,329048,118861.6,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)2>, at::native::<unnamed>::UnaryOpFunctor<float, (int)2, (int)1, (int)1>, at::native::Sqrt<float>>(T1, T2, T3...)"
0.0,13322842,52,256208.5,253130.5,22400,575827,228639.9,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListScalarListMetadata<float, (int)1>, at::native::<unnamed>::BinaryOpScalarListFunctor<float, (int)1, (int)1, (int)0>, std::divides<float>>(T1, T2, T3...)"
0.0,13279292,108,122956.4,121293.5,91006,162300,8612.2,"void at::native::_scatter_gather_elementwise_kernel<(int)128, (int)8, void at::native::_cuda_scatter_fill_internal_kernel<at::native::OpaqueType<(int)4>, long long>::operator ()<at::native::TensorAssign>(at::TensorIterator &, at::native::OpaqueType<(int)4>, long long, long long, long long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,12435286,6,2072547.7,1916962.0,1913970,2430630,244476.2,"void cudnn::cnn::convolveNd_wgrad_engine<__half, (int)3, (int)128, (int)5, (int)5, (int)3, (int)3, (int)3, (bool)0>(int, int, int, const T1 *, int, T1 *, const T1 *, kernel_gradNd_params, unsigned long long, int, float, int)"
0.0,12295299,11664,1054.1,1024.0,960,49439,470.2,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl_nocast<at::native::FillFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,12133265,52,233332.0,229707.0,29855,538484,205291.5,"void at::native::<unnamed>::multi_tensor_apply_kernel<at::native::<unnamed>::TensorListMetadata<(int)1>, at::native::<unnamed>::UnaryOpFunctor<float, (int)1, (int)1, (int)0>, at::native::_amp_foreach_non_finite_check_and_unscale_cuda_(c10::ArrayRef<at::Tensor>, at::Tensor &, const at::Tensor &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(T1, T2, T3...)"
0.0,11531711,108,106775.1,104205.5,102814,138301,7470.4,"void at::native::<unnamed>::cunn_SpatialSoftMaxForward<c10::Half, float, c10::Half, int, at::native::<unnamed>::LogSoftMaxForwardEpilogue>(T3 *, const T1 *, T4, T4, T4)"
0.0,11068269,432,25621.0,25375.0,24127,30271,906.6,void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_64x64_32x6_nn_align8>(T1::Params)
0.0,9077719,108,84053.0,80238.0,78174,463030,36838.2,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<void at::native::<unnamed>::masked_scale_kernel<bool, c10::Half, float>(at::Tensor &, const at::Tensor &, const at::Tensor &, T3)::[lambda(c10::Half, bool) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,9038346,922,9803.0,5952.0,1664,41727,10102.8,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x128x32_stage4_warpsize1x4x1_g1_tensor16x8x16_execute_split_k_kernel__5x_cudnn
0.0,8814112,110,80128.3,80270.0,55103,121021,7967.3,ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_nt
0.0,8703929,864,10074.0,10512.0,6656,18431,2109.9,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIteratorBase &, c10::ArrayRef<long long>, c10::ArrayRef<long long>)::[lambda(char *, const char *, long long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long long>, c10::ArrayRef<long long>, const T1 &, bool)::[lambda(int) (instance 1)]>(long long, T3)"
0.0,8565489,12,713790.8,496740.0,101949,2441446,631583.5,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc2_execute_kernel__5x_cudnn
0.0,8371991,28,298999.7,81070.5,5920,1600346,511032.9,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,8173898,260,31438.1,32639.0,1696,111453,11475.2,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize32x256x32_stage3_warpsize1x4x1_g1_tensor16x8x16_execute_split_k_kernel__5x_cudnn
0.0,7184467,8,898058.4,704671.0,426326,2593409,709623.4,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna2_alignc8_execute_kernel__5x_cudnn
0.0,7143475,4,1785868.8,1779877.0,288825,3294896,1727947.4,"void convolveNd_dgrad_float_engine<__half, (int)3, (int)512, (int)6, (int)5, (int)3, (int)3, (int)3, (bool)0>(int, int, int, const T1 *, int, const T1 *, int, T1 *, kernel_gradNd_params, unsigned long long, int, unsigned long long, int, float, int)"
0.0,7135224,242,29484.4,34495.5,7072,371287,42751.9,sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,6811772,4,1702943.0,1694983.0,289657,3132149,1631312.7,"void convolveNd_dgrad_float_engine<__half, (int)3, (int)128, (int)6, (int)7, (int)3, (int)3, (int)5, (bool)0>(int, int, int, const T1 *, int, const T1 *, int, T1 *, kernel_gradNd_params, unsigned long long, int, unsigned long long, int, float, int)"
0.0,6756637,8,844579.6,774397.5,487156,1350911,386327.3,sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna2_alignc8_execute_kernel__5x_cudnn
0.0,6383606,108,59107.5,57742.5,56639,80094,4186.6,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<c10::Half, at::native::func_wrapper_t<c10::Half, at::native::sum_functor<c10::Half, float, c10::Half>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, c10::Half, (int)4, (int)4>>(T3)"
0.0,6014679,224,26851.2,25967.5,25247,98685,7199.0,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,5960708,226,26374.8,25728.0,6912,87070,6701.8,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,5666872,432,13117.8,13056.0,8384,17951,4603.8,ampere_fp16_s1688gemm_fp16_64x128_sliced1x2_ldg8_f2f_nn
0.0,5619989,432,13009.2,12992.0,12831,13247,74.3,ampere_fp16_s16816gemm_fp16_128x128_ldg8_relu_f2f_stages_64x3_tn
0.0,4962588,864,5743.7,5695.0,5216,7296,291.5,"void at::native::vectorized_elementwise_kernel<(int)2, at::native::BUnaryFunctor<long long, long long, long long, at::native::remainder_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long long, long long) (instance 1)]>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,4545614,216,21044.5,21024.0,20767,23584,198.1,ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_64x4_nt
0.0,3919483,432,9072.9,9087.0,8896,9216,48.9,ampere_fp16_s1688gemm_fp16_64x128_sliced1x2_ldg8_relu_f2f_tn
0.0,3752846,2484,1510.8,1472.0,1312,4992,148.2,"void cublasLt::splitKreduce_kernel<(int)32, (int)16, int, __half, __half, float, __half, (bool)0, __half, __half, __half, (bool)1, (bool)0, (bool)0, (bool)0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)"
0.0,3549743,140,25355.3,9151.0,4512,334616,50380.4,sm86_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,3531018,24,147125.8,92909.5,7488,383383,143970.6,sm86_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,3214995,116,27715.5,7008.0,6847,1208259,156493.0,ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_nt
0.0,3140023,26,120770.1,88702.0,8480,471893,130289.2,sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,3117400,108,28864.8,28863.0,27904,30656,417.9,void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_32x32_64x1_tn_align8>(T1::Params)
0.0,3033984,432,7023.1,7008.0,6911,7136,39.0,ampere_fp16_s16816gemm_fp16_64x64_ldg8_relu_f2f_stages_64x5_tn
0.0,3027799,2808,1078.3,1024.0,960,1440,119.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::batch_norm_calc_invstd(const at::Tensor &, const at::Tensor &, double)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,2953034,2268,1302.0,1152.0,1119,3008,271.8,"void at::native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, (int)4, void at::native::templates::cuda::uniform_and_transform<c10::Half, float, at::CUDAGeneratorImpl *, void at::native::templates::cuda::bernoulli_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void at::native::<unnamed>::distribution_nullary_kernel<c10::Half, float, float4, at::CUDAGeneratorImpl *, void at::native::templates::cuda::uniform_and_transform<c10::Half, float, at::CUDAGeneratorImpl *, void at::native::templates::cuda::bernoulli_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void at::native::templates::cuda::bernoulli_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long long, at::PhiloxCudaState, T3, T4)"
0.0,2725939,438,6223.6,6752.0,4383,7647,1060.6,ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_nn
0.0,2721925,324,8401.0,8352.0,8159,8704,109.7,ampere_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_f2f_nn
0.0,2639553,16,164972.1,2032.0,1280,1217315,410906.9,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, __half, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
0.0,2469479,2268,1088.8,1088.0,896,2112,119.8,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,2230007,112,19910.8,19903.0,19520,20224,134.0,ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_nt
0.0,2135215,116,18407.0,12032.0,8735,354007,44576.3,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_strided_execute_kernel__5x_cudnn
0.0,2131084,6,355180.7,112621.0,55359,901130,420708.6,"void cudnn::dgrad3d_filter2x2x2_stride2x2x2::Kernel_dgrad_3d_ndhwc_float<float, (bool)1, (int)2, (int)2, (int)2, (int)2, (int)2, (int)2, (int)1, (int)1, (int)1>(cudnn::dgrad3d_filter2x2x2_stride2x2x2::KernelParams)"
0.0,2112143,8,264017.9,259162.0,54943,479829,222860.2,"void cudnn::engines_precompiled::setTensor5d_kernel<__half, float, (int)8, (int)8, (int)8>(cudnnTensorStruct, T1 *, T2)"
0.0,2092054,864,2421.4,2400.0,2240,3616,89.7,"void at::native::vectorized_elementwise_kernel<(int)2, at::native::BUnaryFunctor<long long, long long, long long, at::native::binary_internal::div_trunc_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long long, long long) (instance 1)]>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,1975840,864,2286.9,2272.0,2208,2848,51.5,"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::detail::radix::policy_hub<long long, at::cuda::cub::detail::OpaqueType<(int)8>, unsigned long long>::Policy1000, (bool)0, long long, unsigned long long, at_cuda_detail::cub::detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)"
0.0,1968749,864,2278.6,2272.0,2239,6944,160.3,"void <unnamed>::elementwise_kernel_with_index<int, at::native::arange_cuda_out(const c10::Scalar &, const c10::Scalar &, const c10::Scalar &, at::Tensor &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long long) (instance 1)]>(T1, T2, function_traits<T2>::result_type *)"
0.0,1867326,124,15059.1,9472.0,7327,110558,20348.7,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,1696897,216,7856.0,7871.0,7744,8096,35.3,ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x6_nt
0.0,1661529,14,118680.6,68046.5,35679,290745,84573.5,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,1655099,864,1915.6,1920.0,1855,2720,40.7,"void at::native::vectorized_elementwise_kernel<(int)2, at::native::AUnaryFunctor<long long, long long, long long, at::native::binary_internal::MulFunctor<long long>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,1642779,120,13689.8,7936.0,7488,212827,27948.9,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,1581153,112,14117.4,14143.0,13728,14559,121.8,ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_nn
0.0,1444454,112,12896.9,12960.0,11648,13504,317.5,void cutlass::Kernel2<cutlass_80_tensorop_s16816gemm_f16_64x64_32x6_tn_align8>(T1::Params)
0.0,1414974,10,141497.4,52686.5,8128,553075,216559.2,sm80_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,1325312,2,662656.0,662656.0,662512,662800,203.6,sm80_xmma_dgrad_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,1318465,108,12208.0,12287.0,11680,12384,171.0,ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn
0.0,1228519,648,1895.9,2016.0,1440,2880,230.1,"void cublasLt::splitKreduce_kernel<(int)32, (int)16, int, float, __half, float, __half, (bool)0, __half, __half, __half, (bool)1, (bool)0, (bool)0, (bool)0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)"
0.0,1214798,216,5624.1,5615.5,4352,6912,1207.1,ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn
0.0,908910,864,1052.0,1056.0,1023,1536,34.0,"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::detail::radix::policy_hub<long long, at::cuda::cub::detail::OpaqueType<(int)8>, unsigned long long>::Policy1000, unsigned long long>(T2 *)"
0.0,732302,394,1858.6,1824.0,1631,2272,77.0,void xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_1<xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::Params_pre_hopper>(T1)
0.0,664300,648,1025.2,992.0,928,1312,72.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,619341,112,5529.8,5536.0,5056,5856,114.7,ampere_s16816gemm_fp16_64x64_ldg8_stages_64x5_tn
0.0,605741,394,1537.4,1536.0,1312,2112,161.7,"void xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_2<xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::Params_pre_hopper>(T1, int)"
0.0,528695,112,4720.5,4704.0,4512,5056,86.9,ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_32x6_nt
0.0,499574,432,1156.4,1152.0,1055,1376,91.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float>>, std::array<char *, (unsigned long long)3>>(int, T2, T3)"
0.0,445236,394,1130.0,1120.0,1056,2240,114.0,void xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::kernel_helper_stage_0<xmma__5x_cudnn::implicit_gemm::strided_dgrad_indexed::Params_pre_hopper>(T1)
0.0,389333,336,1158.7,1056.0,864,1536,247.8,"void cudnn::cnn::reduce_wgrad_nchw_helper<float, __half>(void *, const void *, T1, int, int)"
0.0,370260,224,1652.9,1600.0,1472,1920,136.0,"void cublasLt::splitKreduce_kernel<(int)32, (int)16, int, float, float, float, float, (bool)0, float, float, float, (bool)1, (bool)0, (bool)0, (bool)0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)"
0.0,353401,6,58900.2,51823.0,51039,74271,11555.6,sm86_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,330296,12,27524.7,18336.0,7039,65630,22172.8,sm86_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x128x64_stage4_warpsize2x2x1_g1_tensor16x8x16_execute_kernel__5x_cudnn
0.0,310520,12,25876.7,2272.0,1248,133661,46416.0,"void cudnn::engines_precompiled::nchwToNhwcKernel<__half, float, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
0.0,243608,216,1127.8,1120.0,1088,1312,28.6,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,241528,216,1118.2,1120.0,1056,1248,27.9,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,229369,108,2123.8,2112.0,2048,2176,20.8,"void at::native::<unnamed>::GammaBetaBackwardCUDAKernelTemplate<float, float, (unsigned int)32, (unsigned int)8, (unsigned int)64, (bool)0, (bool)1>(long long, long long, const T1 *, const T1 *, const T2 *, const T2 *, T1 *, T1 *)"
0.0,219193,108,2029.6,2016.0,1791,2304,46.6,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, (int)4, (int)4>>(T3)"
0.0,214107,14,15293.4,15231.5,9632,20799,2255.8,"void tensorTransformGeneric<__half, __half, float, (bool)1, (bool)0, (bool)0, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long long, const T1 *, T2 *, T3, T3)"
0.0,211547,216,979.4,992.0,960,1024,17.4,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<float>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,165756,108,1534.8,1536.0,1472,1952,48.5,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,161020,4,40255.0,40303.0,38879,41535,1411.1,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn
0.0,122878,108,1137.8,1120.0,1088,1248,25.6,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnOther_add<float>, std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,98877,6,16479.5,11168.0,7871,30495,10817.5,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_strided_execute_kernel__5x_cudnn
0.0,96030,108,889.2,896.0,864,896,13.2,"void at::native::<unnamed>::nll_loss2d_forward_size_average_kernel<float>(T1 *, const T1 *)"
0.0,74847,4,18711.8,18880.0,9824,27263,9824.4,sm86_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1_execute_kernel__5x_cudnn
0.0,62398,4,15599.5,15599.5,8991,22208,7630.3,"void cudnn::engines_precompiled::convertTensor_kernel<__half, float, float, (cudnnKernelDataType_t)2>(T3, const T1 *, T3, T2 *, unsigned long long)"
0.0,44094,2,22047.0,22047.0,21791,22303,362.0,sm80_xmma_dgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_strided_execute_kernel__5x_cudnn
0.0,39583,4,9895.8,9888.0,5920,13887,4481.6,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1_execute_kernel__5x_cudnn
0.0,35968,26,1383.4,1376.0,1248,1600,57.5,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(double) (instance 1)], std::array<char *, (unsigned long long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T4, T5, T6, T7)"
0.0,35391,26,1361.2,1376.0,1184,1536,52.2,"void at::native::vectorized_elementwise_kernel<(int)2, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 1)]::operator ()() const::[lambda(double) (instance 1)], std::array<char *, (unsigned long long)2>>(int, T2, T3)"
0.0,33823,26,1300.9,1312.0,1280,1312,15.5,"at::native::amp_update_scale_cuda_kernel(float *, int *, const float *, double, double, int)"
0.0,17888,2,8944.0,8944.0,8928,8960,22.6,"void cudnn::engines_precompiled::convertTensor_kernel<float, __half, float, (cudnnKernelDataType_t)0>(T3, const T1 *, T3, T2 *, unsigned long long)"
0.0,9984,2,4992.0,4992.0,4928,5056,90.5,sm80_xmma_wgrad_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1_execute_kernel__5x_cudnn
0.0,8768,6,1461.3,1472.0,1344,1536,66.1,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, __half, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
0.0,800,1,800.0,800.0,800,800,0.0,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<int>, std::array<char *, (unsigned long long)1>>(int, T2, T3)"
